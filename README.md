# Latent Space Exploration for Real-Time Particle Reconstruction in the HL-LHC Upgrade                                                                                                                              

Scripts to explore and visualize the latent space generated by a trained auto-encoder during data compression in particle simulations.

## Detailed Overview
The High Luminosity-LHC (HL-LHC) upgrade is expected to produce a dataset more than 10 times larger than is currently available at the Compact Muon Solenoid (CMS) detector. With this increase in statistics comes an increase in pileup (overlapping collisions) and higher radiation levels within the data, introducing further complexity of the particle reconstruction. Particularly, the CMS detector's trigger system, which filteres and selects relevant collision events in real-time, will face an upresedented increased in bottlenecks due to the overwhelming complexity and data volume. To confront this challenge, CMS will upgrade the endcap calorimeter system with a high-granularity calorimeter (HGCal) that will contain millions of silicon sensors. The HGCal will offer unprecedented resolution but pose extreme computational challenege in processing, reducing and analysing particle shower clustering in real-time. Due to this, the configuration of an auto-encoder is being designed to compress the complex dataset coming from the HGCall Trigger Cells into a low-dimensional representation -- while still perserving key information. From this compression, the data can then be directly fed into a Graph Nueral Network (GNN) based clustering algorithm -- replacing traditional sequntial clustering algorithms that struggle to keep up with the increased overlapping of particle showers. This GNN will enable efficient real-time particle reconstruction while meeting the stringent latency constraints (within a few microseconds). Within this context, an clear understanding of the low dimensional latent space determined by the auto-encoder is **absolutely necessary** before the compressed data can be feed into the GNN -- ensuring accurate particle reconstruction in real time.

## Latent Space Visualization 
By visualizing the latent space after training the autoencoder, we can observe how the high dimensional dat (particle shows, energy deposits, etc.) is transformed into a lower dimension respresentaion. This is critical for:

- Identifying cluster patterns in particle interactions
- Evaluating how effectively pileup and other background noise are filtered out by the autoencoder

## Installation 
To install the necessary dependencies for the project, proceed with the following:
1. Clone the repo:
```shell
git clone https://github.com/zabaldwin/LatentSpace-Visual/
```
2. Change directories into the project directory:
```shell
cd LatentSpace-Visual
```
3. Install the required Python packages if necessary:
```shell
pip install -r requirements.txt
```

## Usage 
This project currently depends on simulation data from the CMS High Granularity Colorimeter (HGCal), which models the collection of events that are anticipated during the HL-LHC upgrade. To run the main iPython notebook script, 'LatentSpace_Visualization_NewWeightsStudy.ipynb', which visualizes the embedded latent representations, you will need the saved weights from the original CAE, as well as at least one ntuple.root file from the testing dataset.

## Methodology 

## Demos
This repo will also includes several demonstartions of the different techniques to visualize the latent space... eventaully. They will be found within the `demos/` directory, with brief documentaion on each provided.
